{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pCDBN_draftversion.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQq60_4Sjy2R"
      },
      "source": [
        "ðŸš€A convolutional deep belief network (CDBN) is a type of deep artificial neural network composed of multiple layers of convolutional restricted Boltzmann machines stacked together\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idCtluupt2zN"
      },
      "source": [
        "#Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import pdb\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAm_TUlQp2PX"
      },
      "source": [
        "class pCDBN():\n",
        "\n",
        "    def __init__(self, k, learning_rate=1e-3, momentum_coefficient=0.5, weight_decay=1e-4,num_visible=0, num_hidden=0,batch_size=64,  use_cuda=True):\n",
        "        self.num_visible = num_visible\n",
        "        self.num_hidden = num_hidden\n",
        "        self.batch_size = batch_size\n",
        "        self.k = k #Step for CD\n",
        "        self.learning_rate = learning_rate\n",
        "        self.momentum_coefficient = momentum_coefficient\n",
        "        self.weight_decay = weight_decay\n",
        "        self.use_cuda = use_cuda\n",
        "\n",
        "\n",
        "        self.conv1_weights = nn.Parameter(torch.randn(32,1,4,4))\n",
        "        self.conv1_visible_bias = nn.Parameter(torch.randn(1))\n",
        "        self.conv1_hidden_bias = nn.Parameter(torch.randn(32))\n",
        "        self.maxpool1 = nn.MaxPool2d(3,stride=2,return_indices=True)\n",
        "\n",
        "\n",
        "        self.conv1_weights_momentum = torch.zeros(32,1,4,4)\n",
        "        self.conv1_visible_bias_momentum = torch.zeros(1)\n",
        "        self.conv1_hidden_bias_momentum = torch.zeros(32)\n",
        "        self.upsample1 = nn.MaxUnpool2d(2, stride=1)\n",
        "\n",
        "\n",
        "        if self.use_cuda:\n",
        "            self.conv1_weights = self.conv1_weights.cuda()\n",
        "            self.conv1_visible_bias = self.conv1_visible_bias.cuda()\n",
        "            self.conv1_hidden_bias = self.conv1_hidden_bias.cuda()\n",
        "\n",
        "\n",
        "            self.conv1_weights_momentum = self.conv1_weights_momentum.cuda()\n",
        "            self.conv1_visible_bias_momentum = self.conv1_visible_bias_momentum.cuda()\n",
        "            self.conv1_hidden_bias_momentum = self.conv1_hidden_bias_momentum.cuda()\n",
        "\n",
        "    def sample_hidden(self, visible_probabilities):\n",
        "        out1 = F.conv2d(visible_probabilities,weight=self.conv1_weights,bias=self.conv1_hidden_bias)\n",
        "        out1 = F.leaky_relu(out1)\n",
        "        self.out1,self.out_idc = self.maxpool1(out1)\n",
        "        hidden_probabilities = self.out1\n",
        "        return hidden_probabilities #output\n",
        "\n",
        "    def sample_visible(self, hidden_probabilities):\n",
        "        de_output1 = self.upsample1(hidden_probabilities,self.out_idc)\n",
        "        de_output1 = F.conv_transpose2d(de_output1,weight=self.conv1_weights,bias=self.conv1_visible_bias,stride=2,padding=0)\n",
        "        self.de_output1 = F.leaky_relu(de_output1)\n",
        "\n",
        "        visible_probabilities = self.de_output1\n",
        "\n",
        "        return visible_probabilities\n",
        "\n",
        "    def contrastive_divergence(self, input_data):\n",
        "        # Positive phase\n",
        "        positive_hidden_probabilities = self.sample_hidden(input_data)  #up\n",
        "        pose_scale = positive_hidden_probabilities.size()\n",
        "\n",
        "\n",
        "        positive_hidden_activations = (positive_hidden_probabilities >= self._random_probabilities(pose_scale)).float()\n",
        "        positive_associations = torch.matmul(input_data.view(self.batch_size,784).t(), positive_hidden_activations.view(self.batch_size,pose_scale[1]*pose_scale[2]*pose_scale[3])) \n",
        "\n",
        "        # Negative phase\n",
        "        hidden_activations = positive_hidden_activations\n",
        "\n",
        "        for step in range(self.k):\n",
        "            visible_probabilities = self.sample_visible(hidden_activations)\n",
        "            hidden_probabilities= self.sample_hidden(visible_probabilities)\n",
        "            neg_scale = hidden_probabilities.size()\n",
        "\n",
        "            hidden_activations = (hidden_probabilities >= self._random_probabilities(neg_scale)).float()\n",
        "\n",
        "        negative_visible_probabilities = visible_probabilities\n",
        "\n",
        "        neg_vis_scale = negative_visible_probabilities.size()\n",
        "\n",
        "\n",
        "\n",
        "        negative_hidden_probabilities = hidden_probabilities\n",
        "\n",
        "        neg_hid_scale = negative_hidden_probabilities.size()\n",
        "\n",
        "\n",
        "        negative_associations1 = torch.matmul(negative_visible_probabilities.view(self.batch_size,neg_vis_scale[1]*neg_vis_scale[2]*neg_vis_scale[3]).t(), negative_hidden_probabilities.view(self.batch_size,neg_hid_scale[1]*neg_hid_scale[2]*neg_hid_scale[3]))\n",
        "     \n",
        "        \n",
        "        # Update parameters\n",
        "        self.conv1_weights_momentum *= self.momentum_coefficient\n",
        "        self.conv1_weights_momentum += (1./(144.*49.))*torch.sum((positive_associations.view(144,49,32,1,4,4) - negative_associations1.view(144,49,32,1,4,4)),dim=(0,1))\n",
        "\n",
        "        self.conv1_visible_bias_momentum *= self.momentum_coefficient\n",
        "        vis_bm_tmp = torch.sum(input_data - negative_visible_probabilities, dim=(0,1,2,3))\n",
        "        self.conv1_visible_bias_momentum += (1.0/(64.*28.*28.))*vis_bm_tmp\n",
        "\n",
        "        self.conv1_hidden_bias_momentum *= self.momentum_coefficient\n",
        "        hidden_bm_tmp = torch.sum(positive_hidden_probabilities - negative_hidden_probabilities, dim=(0, 2, 3))\n",
        "        self.conv1_hidden_bias_momentum += (1.0/(64.*12.*12.))*hidden_bm_tmp\n",
        "\n",
        "        batch_size = input_data.size(0)\n",
        "\n",
        "        self.conv1_weights += self.conv1_weights_momentum * self.learning_rate / batch_size\n",
        "        self.conv1_visible_bias += self.conv1_visible_bias_momentum * self.learning_rate / batch_size\n",
        "        self.conv1_hidden_bias += self.conv1_hidden_bias_momentum * self.learning_rate / batch_size\n",
        "        self.conv1_weights -= self.conv1_weights * self.weight_decay  # L2 weight decay\n",
        "\n",
        "        error = torch.sum((input_data - negative_visible_probabilities)**2)\n",
        "        return error\n",
        "\n",
        "    def Chebyshev(self, x):\n",
        "      # L = 7\n",
        "      return (-5*x**7 + 21*x**5 - 35*x**3 + 35*x + 16)/(2.0**5) \n",
        "         \n",
        "    def dpChebyshev(self, x, Delta, epsilon, batch_size):\n",
        "      coefficients = [-5.0, 21.0, -35.0, 35.0, 16.0] \n",
        "        \n",
        "      for i in range(0, len(coefficients)):\n",
        "        perturbFM = np.random.laplace(0.0, 1.0/(epsilon*batch_size), 1).astype(np.float32);\n",
        "        perturbFM = tf.multiply(perturbFM, Delta);\n",
        "        coefficients[i] += perturbFM;\n",
        "        # L = 7\n",
        "        return (tf.multiply(coefficients[0], x**7) + tf.multiply(coefficients[1], x**5) + tf.multiply(coefficients[2], x**3) + tf.multiply(coefficients[3], x**1) + coefficients[4])/(2.0**5)\n",
        "   \n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + torch.exp(-x))\n",
        "\n",
        "    def _random_probabilities(self, num):\n",
        "        random_probabilities = torch.rand(num)\n",
        "\n",
        "        if self.use_cuda:\n",
        "            random_probabilities = random_probabilities.cuda()\n",
        "\n",
        "        return random_probabilities\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}